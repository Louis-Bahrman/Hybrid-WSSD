<!DOCTYPE html>
<html>
  <head>
    <title> Hybrid WSSD </title>
    <meta encoding="utf-8">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300&display=swap" rel="stylesheet"><meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <body>
    <header>
      <div id="title_authors" class="titlecenter"> 
        <h1> A hybrid model for weakly supervised speech dereverberation </h1>
      </div>
      <div class="center">
        <p style="text-align:center">
        <b> Louis Bahrman<sup>1</sup>, Mathieu Fontaine<sup>1</sup>, Gaël Richard<sup>1</sup></b>
        </p>
        <p style="text-align:center"> <sup>1</sup>LTCI, Télécom Paris, IP-Paris, France</p>
        <hr>
      </div>
      <div class="center" style="max-width:600px">
        <div class="container">
          <a href="https://www.github.com/Louis-Bahrman/Hybrid-WSSD">Code</a>
        </div>
      </div>
    </header>
    <div class="center">
      <hr>
    <figure>
      <img class="figure" src="block_diagram.svg" alt="Block diagram">
    </figure>
    <section>
      <h2>Abstract</h2>
      <p>
      This paper introduces a new training strategy to improve speech dereverberation systems using minimal acoustic information and reverberant (wet) speech. Most existing algorithms rely on paired dry/wet data, which is difficult to obtain, or
on target metrics that may not adequately capture reverberation
characteristics and can lead to poor results on non-target
metrics. Our approach uses limited acoustic information, like the
reverberation time (RT60), to train a dereverberation system.
The system’s output is resynthesized using a generated room
impulse response and compared with the original reverberant
speech, providing a novel reverberation matching loss replacing
the standard target metrics. During inference, only the trained
dereverberation model is used. Experimental results demonstrate
that our method achieves more consistent performance across
various objective metrics used in speech dereverberation than
the state-of-the-art.
      </p>
    </section>
    <section>
      <h2>Audio examples</h2>
      <p>WS denotes Weak supervision, by RT60 (proposed) or by SRMR (Baseline)</p>
      <table>
        <tbody>
          <tr>
            <td></td>
            <td>Wet input</td>
            <td>Ground truth</td>
            <td>FSN (proposed)</td>
            <td>FSN</td>
            <td>BiLSTM (proposed)</td>
            <td>BiLSTM</td>
            <td>Baseline</td>
          </tr>
          <tr>
            <td>WS</td>
            <td></td>
            <td></td>
            <td>&#x2717;</td>
            <td>&#x2713;</td>
            <td>&#x2717;</td>
            <td>&#x2713;</td>
            <td>&#x2713;</td>
        </tbody>
      </table>
    </section>
    <section>
        <h2>Citing this work</h2>
        <p>
        If you use this work in your research or business, please cite it using the following BibTeX entry:
        </p>
        <pre>
        <code>
        todo
        </code>
        </pre>
      </section>
  </body>
</html>
